SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

SECTION 280 – MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE
DELIVERY
Table of Contents
280.1
280.2
280.3
280.4
280.5
280.6
280.7
280.8
280.9
280.10
280.11
280.12
280.13
280.14
280.15
280.16

Who is responsible for customer experience and service delivery?
What is Federal government customer experience and service delivery?
How should agencies identify services?
What are agency responsibilities to deliver services and make them available through
multiple channels?
How should agencies collect metrics to analyze digital services?
What is the purpose of implementing this guidance?
How should agencies manage customer experience?
How do these efforts relate to the Paperwork Reduction Act (PRA), reducing burden,
improving access, and engaging customers?
How can agencies know their services are working and delivering value for the public?
How should customer experience be reflected in an agency's Annual Performance Plan?
What programs have been identified as High Impact Service Providers (HISPs)?
What steps should HISPs take to manage customer experience?
How should HISPs designate priority services?
How should HISPs collect and submit "post-transaction" feedback data?
What shall HISP CX Capacity Assessments and Action Plans include?
How should agencies participate in designated Life Experiences?
Summary of Changes

Updates submission dates for required deliverables, provides simplified structures for transaction
surveys and data collection, and outlines leading practices for effective management of customer
experience. This update also provides additional connection between customer research efforts and
the Paperwork Reduction Act, and provides additional detail on the collection of digital analytics
data to augment transactional surveys.

280.1

Who is responsible for customer experience and service delivery?

All Executive agencies (5 U.S.C. 105) have a responsibility to manage customer experience and improve
service delivery using leading practices and a human-centered approach, pursuant to Executive Order 14058
("E.O. 14058") on Transforming Federal Customer Experience and Service Delivery To Rebuild Trust in
Government of December 13, 2021, and the 21st Century Integrated Digital Experience Act (P.L. 115-336)
("21st Century IDEA"). All agencies should apply the guidance provided in this section for annual customer
experience management and planning, as well as the design of feedback surveys and measurement strategies
for the performance of Federal services. This guidance provides detail on activities to be conducted by
designated High Impact Service Providers (HISPs, as defined in section 280.11), which are required to
implement the guidance in sections 280.12 through 280.15.
280.2

What is Federal government customer experience and service delivery?

It is the Federal government's responsibility to ensure that every interaction a member of the public has
with their government demonstrates competence and transparency and builds trust. As defined by E.O.

OMB Circular No. A-11 (2023)

Page 1 of Section 280

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

14058, the term "customer experience" ("CX") means the public's perceptions of and overall satisfaction
with interactions with an agency, product, or service. 1 Building on this definition and applied in the broader
context of this Section and the Federal Performance Framework, the term refers to a combination of factors
that result from touchpoints between an individual, business, or organization and the Federal government
over the duration of an interaction, service journey, and relationship. These factors of experience can
include: ease/simplicity/effort (burden/friction), efficiency/speed, transparency, equity (e.g., participation,
access), humanity (e.g., respect, dignity, empathy), effectiveness/perceived value of the service itself, and
interactions with any employees. Perceived responsiveness to individual needs and ability to provide
feedback is also important. 2 Similar to their application in the private sector, these factors can drive the
overall satisfaction with and trust in the program, agency, and the government at large. A customer's
experience interacting with the Federal government directly contributes to their trust in government itself. 3
To that end, measures of experience are of co-equal importance as traditional measures of financial and
operational performance, and which this document begins to outline an accountability framework to deliver.
Services are the unit of observation for this performance accountability irrespective of perceived current
ownership or budgetary/organizational lines. "Service delivery" means the actions taken by an organization,
such as the Federal government, related to providing a benefit or service to a customer of a Federal
government entity; the term refers to the multitude of diverse interactions between a customer and Federal
agency. The Federal customer experience framework is centered on services. Services are a more welldefined unit of observation for customer experience management than a Federal program. In many sectors,
the service, even more so than the offering or end product, determines the customer's satisfaction and the
reputation of the organization or brand. Other factors affect customers' total experience – the environment,
prior interactions, etc. – but the service is the most critical part controlled by the entity.
Today, citizens are dissatisfied with government services when compared against the private sector, which
has leveraged technology, process re-design, self-service, empowered front lines, and other tactics to raise
expectations. All Federal agencies should have knowledge, and in some instances documentation, of the
services they provide (e.g., SNAP recertification, land border checkpoints, business tax filing) and should
be able to articulate how the components of the services, such as the occasion, offering, channels, roles,
and tools, come together to make up the agencies' approach to service design and delivery.
The Federal customer experience framework is intended to provide agencies with a clear approach and
roadmap for aligning service design with customer needs. For definitions of terms (such as "services" and
service types) used in the previous paragraphs as well as others relating to CX and service delivery, please
see https://performance.gov/cx/terms.
280.3

How should agencies identify services?

The 21st Century IDEA requires all Executive agencies (5 U.S.C. 105) to identify public non-digital, paperbased, or in-person government services for purposes of digitization. To fulfill this requirement, OMB
requires agencies to develop an inventory of all services – digital, non-digital, paper-based, and in-person
–offered to their primary customers, tasks to get or manage each service, and channels available to complete
each task (e.g., online, in person, phone, mail, paper, etc.) and submit this information to OMB.
1 E.O. 14058 defined critical terms like "Customer Experience." A list of related terms and their definitions can be found here:

https://performance.gov/cx/terms

2 The OECD has done work to demonstrate that "government's competence - its responsiveness and reliability in delivering

public services and anticipating new needs - are crucial for boosting trust in institutions." See https://www.oecd.org/gov/trust-ingovernment.htm.
3 A recent analysis reveals that 67 percent of the public's trust in government comes from their experience with government
programs. See https://www.mckinsey.com/industries/public-and-social-sector/our-insights/Customer-Experience-in-the-PublicSector.

Page 2 of Section 280

OMB Circular No. A-11 (2023)

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

280.4

What are agency responsibilities to deliver services and make them available through
multiple channels?

Service delivery through multiple channels increases access and participation, ensuring that government
services are available to all – including those who need them the most, such as underserved communities.
Agencies are encouraged to leverage a multi-channel approach – as is appropriate, feasible, and supported
by customer research – including both traditional (e.g., in-person, postal mail, or phone) and digital
channels, to ensure the equitable and effective delivery of services. Agencies should maintain accessible
methods for completing services to enable individuals without sufficient access to information technology
and/or digital literacy to successfully utilize those services.
280.5

How should agencies collect metrics to analyze digital services?

Agencies should ensure, to the greatest extent practicable, that all services and tasks are made available
through digital channels using industry leading practices and human-centered design. Examples of digital
service channels include websites, mobile apps, email, text messaging, and social media.
In general, and consistent with the requirements in OMB Memoranda M-10-22 of June 25, 2010, Guidance
for Online Use of Web Measurement and Customization Technologies agencies should use the following
leading practices for gathering and analyzing metrics for digital services:
•

In designing metrics for a website or web application, agencies should work backward from
customer insights and strategic questions. Agencies should define specific actions they plan to take
to improve digital experience with the service or product based on insights derived from digital
analytics.

•

An agency's digital analytics program (e.g., the General Services Administration's Digital Analytics
Program) should capture data from key customer actions, such as button clicks, page views, and
transactions.

•

Attach timestamps to data points to trace a user's journey through time as well as analyze macrolevel shifts in user behavior over longer time periods.

•

Collect website and web application metrics on a continuous basis to observe longitudinal trends.

•

Website and web application data should be collected in a structured and machine-readable format
to facilitate quantitative aggregation (e.g., sum, median, mean, minimum, maximum) of customer
behavior data for analytics and monitoring.

•

Agencies are encouraged to implement continuous monitoring and dashboards to proactively
visualize when there has been a significant change or regression in the customer's digital experience
(e.g., if page views or volume of key transactions has suddenly dropped). Implementing alarms to
send alerts when critical metrics have regressed allows for immediate corrective action.

•

As new user flows are added, digital analytics should be implemented at the launch of the new
feature to ensure comprehensive monitoring of customer digital experience. Changes to continuous
monitoring and dashboards should reflect any user flows that are optimized, deprecated, or
replaced.

OMB Circular No. A-11 (2023)

Page 3 of Section 280

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

Customer experience transactional data generates perceptions of trust, confidence, and satisfaction with
government services (see section 280.14). The collection and use of website and web application data may
be used to augment point-in-time data and may also be instrumental for evaluating an agency's changes to
digital services that enhance customer interactions and experiences.
280.6

What is the purpose of implementing this guidance?

Implementing the guidance specified in this section will establish a more consistent, comprehensive, robust,
and deliberate approach to CX across government. The purpose of this guidance is to:
•

Increase agencies' understanding of customers' needs and measure continuous improvement of
Federal government services to better meet customers' priorities;

•

Establish a CX-mindful culture across Federal government services;

•

Improve customer trust in Federal government;

•

Provide structure and consistency around how agencies/programs approach CX;

•

Promote accountability and governance mechanisms to improve service design, quality and service;

•

Ensure Federal service providers are making progress in growing CX program maturity, service
definition, and applying leading practices 4;

•

Ensure Federal service providers are receiving and acting upon customer feedback to drive
performance improvement and service recovery;

•

Allow for government-wide comparative assessment of trust in government following interactions;

•

Ensure transparency through informed consent and public reporting; and,

•

Encourage the application of human-centered design as foundational to achieving customer
experience outcomes.

280.7

How should agencies manage customer experience?

At multiple levels of government organizations (departmental enterprise, bureau, program office, service
center), elements of core CX functions should be present. 5 These include:
•

Measurement: Defining and instituting CX outcome measures, as well as service operational
measures, to ensure accountability for improving service delivery and communicating performance
across the organization and to the public, routinely analyzing and making use of this data;

•

Governance and Strategy: Institutionalizing CX by identifying executives and leaders responsible,
organizing supporting resources, defining the processes by which strategic decisions incorporate

For examples of leading practices and industry frameworks for managing customer experience, please review the
annual CX Capacity Assessment template provided on performance.gov/cx.
5
For a practitioner's guide on implementing CX core functions and capabilities, see the CX Cookbook,
https://www.performance.gov/cx/assets/files/va-customer-experience-cookbook.pdf.
4

Page 4 of Section 280

OMB Circular No. A-11 (2023)

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

customer perspective, and aligning CX strategy and activities with business decisions, initiatives
and investments within the agency's broader mission and strategic priorities;
•

Culture and Organization: Acquiring and developing the talent required to incorporate and
improve CX within agency activities, and empowering all employees to adopt a CX mindset
through training, performance measurement, and rewards;

•

Customer Understanding: Identifying the main occasions that result in the public making use of or
interacting with Federal services and conducting qualitative and quantitative research across
organizational silos to map intra-agency customer journeys, as well as cross-agency journeys where
applicable, to build and continually refine a knowledge base of the agency's customer segments and
needs, integrating disparate customer interaction and administrative data; and,

•

Service Design and Improvement: Adopting a customer-focused approach to the implementation
of services, involving and engaging internal and external customers in feedback gathering and
iterative development, designing and building digital products and services, adopting leading
practices to deliver more efficient and effective interactions, and sharing lessons learned across
government.

Each fiscal year, Executive agencies should reflect on their maturity and capacity to perform these
functions, such as during strategic review, annual planning, and in executing requirements outlined in this
section. Further, agencies and programs should develop an understanding of the types of and explicit
definition of the services they offer (as defined in sections 280.2 and 280.3); this should include an
assessment of the talent they have to perform and oversee these functions, and specifically identify needs
for hiring individuals with the expertise and experience into their agency.
280.8

How do these efforts relate to the Paperwork Reduction Act (PRA), reducing burden,
improving access, and engaging customers?

Engaging customers and speaking directly with the public is a central component of human-centered design
and leads to a better understanding of the problems faced by the public, including underserved communities,
which helps agencies design solutions that are more responsive to the needs of the American people. The
surveys described in section 280.14 are not the only methods through which agencies can engage with
customers. When developing approaches to customer engagement, research, and feedback gathering,
agencies should also consider burdens placed on individuals and groups most affected by information
collection related to accessing and maintaining eligibility for public benefits programs. 6
Agencies are to submit the feedback surveys described in section 280.14 for approval under the PRA using
the OMB Circular A-11 Section 280 Umbrella Clearance that can be established at the department level
using the templates provided on the Customer Experience Collections MAX Page. Individual collection
requests under this clearance will be reviewed by OMB's CX Desk Officer in collaboration with the relevant
policy analyst in OMB's Office of Information and Regulatory Affairs (OIRA) in an effort to further
harmonize the review of these types of collections. These umbrella clearances provide a framework for
conducting qualitative customer research and user testing, both of which seek to involve the individuals
and organizations that agencies serve in the actual design and improvement of those services.
Considering burden is in alignment with E.O. 14058, E.O. 13985 of January 25, 2021, on Advancing Racial Equity
and Support for Underserved Communities Through the Federal Government, E.O. 14091 of February 16, 2023, on
Further Advancing Racial Equity and Support for Underserved Communities Through The Federal Government and
OMB Memorandum M-22-10 of April 13, 2022, Improving Access to Public Benefits Programs Through the
Paperwork Reduction Act.
6

OMB Circular No. A-11 (2023)

Page 5 of Section 280

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

Outside of the OMB Circular A-11 Section 280 Clearance, agencies are able to explore other opportunities
for customer engagement. Agencies should note that approval under the Paperwork Reduction Act is not
always required when speaking with members of the public, and OIRA has published extensive guidelines
that can help guide agencies to appropriate flexibilities. Below are a few highlights that may be useful when
an agency is looking to learn about the public's experience with their services:
•

Nine or Fewer Members of the Public: PRA approval is not needed when an agency is speaking
with nine or fewer members of the public. Often discovery and design work can be accomplished
effectively with nine or fewer people, such as through interviews, focus groups, or product testing.
However, using multiple groups of nine for the same purpose or with the same set of questions
would require PRA approval.

•

Recruiting 10 or More Members of the Public: The applicability of the PRA for recruiting members
of the public depends on the intention and specifics of the request. For example, asking if people
are interested in participating and, if so, to send contact information for attendance does not require
a PRA approval; asking one or more screening questions (orally or in writing), such as
"what zip code do you live in?" and "to what degree do you use this service?" will require a PRA
approval.

•

Open-Ended Questions During the Design/Discovery Phase: Conducting unscripted conversations
in the design or discovery phase will not generally require PRA approval (e.g., displaying a
prototype or service and asking for general thoughts and reactions, asking participants to narrate
their experience of using a product or service, and asking questions during a public listening session
to promote discussion).

•

Post-Transaction Data Collection of 10 or More Individuals: PRA approval is needed for posttransaction surveys (assuming an agency is surveying 10 or more individuals). When data is being
collected to understand and continuously improve an existing product or service (not during the
design and discovery phases), the PRA will apply.

Increasingly, agencies are recognizing the importance of including hard-to-reach populations, particularly
those from underserved communities, in their samples in order to improve the quality and representation of
customer research. If your agency wishes to provide compensation or incentives to participants in focus
groups or other similarly time and effort-intensive feedback surveys, the first step is to have a conversation
with your agency's legal counsel to determine whether your agency may offer incentives, and if so, what
kind and in what amount. If your agency's legal counsel approves providing incentives to participants, you
will need to justify these incentives in the Information Collection Review package you submit to OMB.
Contact the OMB CX Desk Officer for an example of what a justification for incentives should look like
for purposes of the PRA submission to OMB.
280.9

How can agencies know their services are working and delivering value for the public?

Traditionally, agencies have solely used output and program integrity measures to assess performance.
Under E.O. 14058, experience measures are considered equally as important as operational measures. There
are various ways agencies should be collecting and using customer experience measures to monitor,
improve, and report on the customer experience of their designated services. The following activities are
core components of effective service delivery at an agency:
•

Customer Research Activities: Customer research is one of the first steps agencies can take to better
understand their customers and is generally associated with the discovery phase of the CX journey.
Customer research enables agencies to learn who their customers are, their specific needs, and what

Page 6 of Section 280

OMB Circular No. A-11 (2023)

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

pain points exist, among other insights. Research can be conducted in both structured (e.g., a
customer survey, a focus group) and unstructured (e.g., in-person customer observation, reviewing
social media messages). Common products resulting from customer research include user personas,
customer segments, and journey maps.
•

User Feedback Activities: User feedback typically involves using tangible artifacts to help better
understand how users will react or interact with a new or improved product or service (e.g.,
assessing customer reactions to a plan language rewrite of a website, launching a prototype of a
new digital form). User feedback activities can be conducted in many formats including user
observations, focus groups, card sorting, usability studies, A/B testing, and other methods.

•

Post-Transaction Feedback Data Collection: Post-transaction feedback is any feedback that is
collected from customers after they have engaged with a provider at a moment in their service
journey. Typically, a post-transaction survey collects data on measures such as trust and other
drivers of experience. With some exceptions, OMB defines post-transaction feedback as the 48hour period following the end of a customer interaction with a service, acknowledging that the most
appropriate post-transaction feedback opportunity may vary by the type of service.

•

Data-Driven Decision-Making: Data gathered by agencies (e.g., administrative data, systems data,
digital analytics data, post-transaction feedback data, etc.) should form a customer listening data
ecosystem that informs agency decision-making, goalsetting, and strategic planning. Data should
be made available to staff directly managing service delivery, as well as leadership overseeing
agency priority-setting on a regular and consistent basis. Agencies should also ensure staff exist
within the organization that have the skillset and experience to analyze and communicate various
data. Where practical, agencies should integrate customer experience measures into existing
dashboards of operational metrics in ways that consider specifics of service delivery, such as
differentiating
between
channels,
regions,
and
customer
segments.

•

Voice of the Customer (VOC) Programs: A VOC program is a systematic approach for collecting,
analyzing, and taking actions based on the customer feedback data that an organization collects.
Data types may include structured sources (e.g., end of interaction; end of journey feedback
surveys), and unstructured sources (e.g., emails, online reviews, social media messaging, chats, and
call center notes). A mature VOC program includes three core elements: 1) an enterprise surveying
platform that is able to solicit, ingest, analyze, and visualize customer feedback, as well as integrate
with operational, digital analytics, and case management data; 2) sufficient agency staffing to
monitor, analyze, and interpret key transaction points and trends across time; and, 3) a business
process change whereby agencies are engaging leadership and frontline staff with the data to arrive
at shared understanding of customer concerns and to co-design and implement improvements.

280.10 How should customer experience be reflected in an agency's Annual Performance Plan?
Agency Annual Performance Plans should include indicators for outcomes related to customer experience
and relevant service levels. This should include customer feedback data collected as described below in
section 280.14, as well as service level indicators (e.g., wait times, website analytics) appropriate to their
program. More information on integrating this information into the Annual Performance Plan is included
in section 210.
280.11 What programs have been identified as High Impact Service Providers (HISPs)?
As defined in E.O. 14058, High Impact Service Providers are those Federal entities designated by OMB
that provide or fund high-impact customer-facing services, either due to a large customer base or a high
OMB Circular No. A-11 (2023)

Page 7 of Section 280

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

impact on those served by the program. The list of HISPs is reviewed and updated periodically by OMB.
The current list of HISPs is available at www.performance.gov/HISPs.
The senior accountable official for the HISP (or appropriate senior official) shall coordinate activities
described in section 280.12 for the enterprise. In addition to relevant program and field office staff, these
activities should serve as intra-agency convening mechanisms around the customers served and involve
cross-cutting representation from mission support functions within the agency, including the Chief
Information Officer, Chief Human Capital Officer, Chief Financial Officer, Performance Improvement
Officer, Evaluation Officer, Chief Data Officer, and Customer Experience / Digital Service Teams.
280.12 What steps should HISPs take to manage customer experience?
Given the significance of the services they provide and the requirements in E.O. 14058, HISPs must:
•

In collaboration with OMB, designate at least two (2) priority services, in alignment with the
requirements of the 21st Century IDEA and guidance outlined in this section, for focused
assessment and the activities of this guidance (by May 31, 2024);

•

Collect customer feedback in accordance with section 280.14 for identified moments that matter
along designated service journeys (e.g., no longer sufficient to only report general call center
satisfaction measures without the context of a service journey);

•

Submit this feedback data to OMB at a minimum quarterly, until feedback data is provided directly
to Performance.gov through an open application programming interface (API) (once developed).
Quarterly submissions will be due the last business day of the month following the last day of the
quarter; for FY 2024, these due dates are January 31, April 30, July 31, and October 31, 2024;

•

Conduct an annual CX Capacity Assessment (submitted to OMB by February 23, 2024) for both
HISPs and HISP-maintaining departments and discuss the resulting findings with OMB at an
annual CX Deep Dive (completed by April 14, 2024);

•

Develop a draft CX Action Plan (submitted to OMB by May 31, 2024) and final CX Action Plan
(submitted to OMB, along with the budget submission, by September 9, 2024) annually for each
designated HISP and HISP-maintaining department, with a focus on improvement actions for
designated services; and,

•

As directed in E.O. 14058, embed more customer-focused practices into their service design and
delivery such as conducting service assessments, customer research through qualitative and
quantitative research and journey mapping, approaching more holistic calculations of burden
(learning, compliance, and psychological costs, in accordance with OMB Memorandum M-22-10)
for their service transactions and full journeys, and continually user-test program elements with
customers to refine and improve.

280.13 How should HISPs designate priority services?
Annually, based on an agency's knowledge of existing services (e.g., as in alignment with an agency's list
of services in the Federal Services Index), each HISP is required to designate two or more of these services
for targeted customer experience improvement efforts. These services will be the subject of CX Capacity
Assessment and Action Plans, will be highlighted on www.performance.gov/cx, and will be the focus of
customer feedback data submitted quarterly and shared publicly.

Page 8 of Section 280

OMB Circular No. A-11 (2023)

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

As HISPs determine which services to designate, they should consider designating priority services that
focus on the one or two most important things the HISP does to serve its customers (e.g., high percentage
of the population served, high volume of annual transactions, outsized impact in the lives of the people
served [i.e., where successful use of the services has a consequential impact on the livelihood of an
individual group, such as Tribal members' access to trust assets, an individual applying for benefits under
the Energy Employees Occupational Illness Compensation program]). Importance can be defined in several
different ways, but each HISP should be able to clearly articulate why choosing this service drives value to
the organization and to customers and contributes to the performance of the agency, and should utilize data
to determine which services to prioritize.
HISPs should also consider OMB Memorandum M-22-10, of April 13, 2022, Improving Access to Public
Benefits Programs Through the Paperwork Reduction Act when choosing services to designate. OMB
Memorandum M-22-10 provides guidance to help agencies identify and reduce burdens related to
applying for and maintaining eligibility for public benefits programs, with a particular focus on members
of underserved and marginalized communities.
HISPs should remember that services require action and should be considered through the lens of the
customer: services involve actions taken by customers to accomplish tasks, receive benefits, submit
information, or otherwise engage with an agency HISPs should also consider how designated services relate
to their agency strategy plans, priority goals, learning agendas, equity plans, organizational health measures,
and other planning processes.
280.14 How should HISPs collect and submit "post-transaction" feedback data?
To assist in developing comparable, government-wide scores that enable cross-agency benchmarking
(when relevant), identify those improvements and service elements that most effectively improve trust for
different service types, and reduce burden on the public, programs providing services to the public should
measure their touchpoint and transactional performance in line with industry leading practices for customer
feedback surveys.
OMB outlines three types of customer feedback surveys:
•

Post-Interaction: The customer recently completed (generally defined as within the last 48 hours)
a single, stand-alone interaction (e.g., a survey after viewing a website to find a piece of
information to initiate a service journey, or speaking with a contact center employee).

•

Post-Service Journey: The customer completed a series of interactions or a multi-stage process of
a service (e.g., a survey after the process for applying for and receiving Federal student aid, filing
an individual tax return, or a specific period of someone's life that included transacting with
services such as one-month post-partum).

•

Relational: The customer completed multiple transactions, service journeys, or a lifetime of
engagement with the agency (e.g., a survey after a customer's most recent year of interacting with
an agency or program) and is asked to reflect on their transactions at a point-in-time when a sample
is collected, rather than based on a single, specific transaction.

HISPs must implement at least one customer feedback survey for each of their current designated services.
If only doing one survey for a service, HISPs must implement a customer feedback survey at the completion
of the service journey. HISPs may deploy multiple or as many post-transaction customer feedback surveys
per designated services as needed and appropriate. HISPs should work with OMB to determine
opportunities for post-transaction customer feedback that are most relevant and appropriate for their
designated services, and provide data that enables the ongoing delivery and improvement of the services.
OMB Circular No. A-11 (2023)

Page 9 of Section 280

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

The below framework, including question wording, response architecture, and branching logic, seeks to
reduce burden on the public and to assist in developing comparable, government-wide customer experience
measures that can be shared publicly. All HISPs should consider switching to this model, although
exceptions will be made for HISPs that have demonstrated success with the current model and facility with
and capacity to use more granular data. All post-transaction customer feedback surveys will require PRA
approval under the OMB Circular A-11 Section 280 Umbrella Clearance. HISPs that shift to this more
streamlined framework will be part of discussions regarding results of this model as OMB considers further
implementation in FY 2024.
HISP customer feedback surveys must include:
Q1 Required Wording: This [interaction / service] increased my trust in [High Impact Service Provider].

If a HISP would prefer to use a statement with a Likert scale rating, rather than a binary question, for respondent's agreement
with that statement, adapted wording and scale will be reviewed as part of the PRA approval process. Please note that if a
HISP does employ a 5-point rating scale, OMB will work with them to understand whether and how different ratings (3, 4, 5
/ 5) will be included in OMB's overall trust calculations to be incorporated in the percentage of respondents that responded in
the affirmative on trust in OMB data visualizations and reporting.
Depending on the service and transaction context, other iterations of wording for this question could include sentences such
as:
•
Based on my experience calling the IRS, I trust IRS is working in the best interest of the American public.
•
Having completed FAFSA, I trust FSA to deliver on its responsibility to students.

If respondent provides "thumbs up" or 5-point rating:
Q2a Required Wording: What about this interaction made the difference? (Tap/Select all that apply)
Driver
Corresponding Statement
(Not shown)

Status

(HISPs may choose one statement per category to be shown in a multiple-selection
question format.)
My need was addressed.
My issue was resolved.
I found what I needed.
1
Effectiveness
Required
My question was answered.
(Or similar.)
It was easy to complete what I needed to do.
2
Ease
It was easy to find what I needed.
Required
(Or similar.)
It took a reasonable amount of time to do what I needed to do.
3
Efficiency
I found what I needed on the site quickly.
Required
(Or similar.)
I understand what was being asked of me throughout the process.
Required if
4
Transparency
I understand the reason for the [Agency/Program/service]'s decision.
applicable
(Or similar.)
Humanity /
I was treated fairly.
Required if
5
Equity
(Or similar.)
applicable
Employees I interacted with were helpful.
Employee
Required if
6
The call center representative was committed to solving my problem.
Interaction
applicable
(Or similar.)
Something else.
7
Other
None of the above.
If applicable
(Or similar).)
HISPs are encouraged to the extent possible to simplify statements to 1-3-word clauses and use iconography as relevant.

Page 10 of Section 280

OMB Circular No. A-11 (2023)

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

If respondent provides "thumbs down" or 1-4-point rating:
Q2b Required Wording: What could have been better? (Tap/Select all that apply)
Driver
Corresponding Statement

Status
(HISPs may choose one statement per category to be shown in a multiple selection
question format.)
My need was not addressed.
My issue was not resolved.
1
Effectiveness
Required
I did not find what I needed.
My question was not answered.
(Or similar.)
It was difficult to complete what I needed to do.
2
Ease
It was difficult to find what I needed.
Required
(Or similar.)
It took too long to do what I needed to do.
3
Efficiency
I did not find what I needed on the site quickly.
Required
(Or similar.)
I did not understand what was being asked of me throughout the process.
Required if
4
Transparency
I did not understand the reason for the [Agency/Program/Service]'s decision.
applicable
(Or similar.)
I was not treated fairly.
Required if
5
Humanity
(Or similar.)
applicable
Employees I interacted with were not helpful.
Required if
Employee
6
The call center representative was not committed to solving my problem.
applicable
Interaction
(Or similar.)
Something else.
7
Other
None of the above.
If applicable
(Or similar).)
HISPs are encouraged to the extent possible to simplify statements to 1-3-word clauses and use iconography as relevant.
(Not shown)

Q3 Required Wording: Anything else you want us to know about your experience? (Or similar.)
[Free text response]
May be excluded if format, such as an interactive voice response (IVR)-based survey, does not enable.

Additional considerations:
• If applicable and appropriate, HISPs may include additional questions that enable the HISP to
collect more useful data, such as a question regarding the purpose of a visit or call. The best practice
is that the total survey length should be no more than 15 questions and five minutes of burden (in
addition to accounting for the PRA considerations in section 280.9). Any additional questions
should be placed after the required questions outlined above. All questions on the survey must be
optional for respondents, meaning that a respondent's decision to not answer one or more questions
on the survey will not in any way affect the respondent's receipt of benefits or services, subject
them to any penalties, or otherwise negatively impact them.
• HISPs should administer surveys by applying practices that promote the validity, accuracy, and
utility of the data and that facilitate ease of response. For example, to promote ease of response,
HISPs can use methods such as presenting only a single-screen (even on a mobile device) version
of the survey.
• To the extent possible, HISPs may use sampling techniques on high-volume transactions to split a
long survey into several shorter surveys to reduce burden on the respondents while collecting
sufficient data from a larger pool. HISPs must consult with OMB through the PRA approval process
prior to implementation to ensure survey validity.
• HISPs should deploy post-transaction feedback survey(s) in the channels (e.g., mail, phone, online,
email, texting, in-person, etc.) that are appropriate and relevant to the experience of the customers
for that service (e.g., if a service includes visits to a government webpage, surveying online makes
sense; if a service is paper-based, a paper survey with both mail-in and phone option is appropriate).

OMB Circular No. A-11 (2023)

Page 11 of Section 280

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

•

OMB will work with HISPs to determine whether they should use binary questions or whether they
should use Likert-scale, given the relevant context of each particular HISP. In working with HISPs
to assist them in making this determination, OMB will consider factors including data quality and
validity, aggregating metrics, and granularity.

How to Submit Feedback Data to OMB
HISPs are required to report quarterly post-transaction feedback data on each of their current designated
services (i.e., one post-transaction feedback survey for each current designated service, each quarter).
HISPs may report data from multiple post-transaction feedback surveys for each designated service, if
relevant and appropriate. HISPs will be asked to identify the point-in-time of each post-transaction feedback
data collection during reporting. HISPs must also submit raw data for Questions 1 and 2 so that OMB may
conduct analysis on drivers tapped for individual trust responses. A data reporting template will be provided
on the CX MAX Community page. The template includes instructions, a section for reporting on the
customer experience measures outlined in this section, a placeholder for program-specific service-level
indicators as appropriate, and space to summarize recent accomplishments.
Submissions will be due the last business day of the month following the last day of the quarter: for FY
2024, these due dates are January 31, April 30, July 31, and October 31, 2024. HISPs (many of which are
collecting data in real-time) should submit their data as soon as they are able following the last day of the
quarter. Feedback data will be made available publicly on performance.gov in coordination with OIRA.
Agency-specific post-transaction feedback data are currently published on performance.gov/cx and can be
included in the Annual Agency Performance Plan (see section 280.10). A Federal-level trust measure and
success target is published on https://www.performance.gov/pma/cx/data/. 7
When OMB and HISP designate a new service, the HISP has a maximum of 365 calendar days from the
date of designation to develop a post-transaction feedback data collection survey for the designated service
and to begin quarterly data reporting.
280.15 What shall HISP CX Capacity Assessments and Action Plans include?
The content of CX Capacity Assessments shall address the core CX functions at the HISP enterprise-level
outlined in section 280.7 as well as the results of designated service assessments. Further, HISPs
maintaining department-level CX organizations will also be asked to complete an annual CX Capacity
Assessment.
The content of the CX Action Plans shall address specific delivery improvements to designated services,
as well as actions to improve the maturity of CX and service delivery capabilities and capacity. This
includes updates to current year priorities, adjustments to the following year's priorities, and proposals to
be considered in the formulation of the next President's Budget (in this case, FY 2026). Actions should
address pain points identified through service assessments, customer feedback, human-centered design
research, and other evidence generation activities. CX Action Plans should focus on customer outcomes
and should communicate what success will look like in terms of what any proposed improvements will
mean for an individual customer using the service. Commitments will be made publicly available on
performance.gov/cx.

7

Agencies seeking to create an agency-specific CX reporting website (i.e., agency.gov/cx) highlighting their CX
efforts should contact OMB so that reporting duplication and overlap can be minimized.

Page 12 of Section 280

OMB Circular No. A-11 (2023)

SECTION 280—MANAGING CUSTOMER EXPERIENCE AND IMPROVING SERVICE DELIVERY

An annual HISP CX Capacity Assessment and Action Plan template will be made available on the CX
MAX Community page.
280.16 How should agencies participate in designated Life Experiences?
OMB will manage the selection of a limited number of customer life experiences to prioritize for
Government-wide action to improve customer experience in line with the cadence of the President's
Management Agenda. These designated life experiences are those that require members of the public to
navigate a service or services across the boundaries of multiple Federal programs, agencies, or levels of
government. OMB will provide leadership, policy consultation, and reporting in accordance with E.O.
14058, a governance structure, and support to agencies through the President's Management Council. The
charters for these designated Life Experience portfolios will be made publicly available at
http://www.performance.gov/cx. Additionally, individual Life Experience project milestones and
deliverables will be made available at https://www.performance.gov/pma/cx/strategy/2/.
The full Life Experience program cycle includes a Discovery phase to understand people's experiences and
opportunities for improvement, a Design phase of building and testing solutions, a Delivery phase to scale
the interventions and products that work, and continuous Measurement to ensure the designs are working
to reach outcomes. Agencies and their staff will participate in a variety of ways across Life Experience
portfolios and projects, including serving as subject matter experts to contribute to and review materials,
serving on interagency delivery teams, providing programmatic leadership for a given project, providing
data that enables more streamlined delivery, supporting procurement by leveraging best-in-class contracting
vehicles, or other ways of supporting projects.
Per E.O. 14058, the Director of OMB shall work with the head of each relevant agency to help resolve
issues related to overlapping responsibilities among agencies, to address barriers serving customers across
multiple agencies, and to coordinate activities to improve customer experience and services delivery when
the primary responsibility among multiple agencies is unclear. 8

Section 5(d), E.O. 14058 of December 16, 2021, on Transforming Federal Customer Experience and Service
Delivery To Rebuild Trust in Government, available at https://www.federalregister.gov/documents/2021/12/16/202127380/transforming-federal-customer-experience-and-service-delivery-to-rebuild-trust-in-government.
8

OMB Circular No. A-11 (2023)

Page 13 of Section 280

